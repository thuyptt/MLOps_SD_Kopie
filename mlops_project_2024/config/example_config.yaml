arguments:
  - name: pretrained_model_name_or_path
    type: str
    default: dreamlike-art/dreamlike-photoreal-2.0
    required: true
    help: Path to pretrained model or model identifier from huggingface.co/models.
  - name: revision
    type: str
    default: null
    required: false
    help: Revision of pretrained model identifier from huggingface.co/models.
  - name: variant
    type: str
    default: null
    required: false
    help: Variant of the model files of the pretrained model identifier from huggingface.co/models, 'e.g.' fp16
  - name: dataset_name
    type: str
    default: null
    required: false
    help: The name of the Dataset (from the HuggingFace hub) to train on (could be your own, possibly private, dataset). It can also be a path pointing to a local copy of a dataset in your filesystem, or to a folder containing files that ðŸ¤— Datasets can understand.
  - name: dataset_config_name
    type: str
    default: null
    required: false
    help: The config of the Dataset, leave as None if there's only one config.
  - name: train_data_dir
    type: str
    default: "./data/raw"
    required: false
    help: A folder containing the training data. Folder contents must follow the structure described in https://huggingface.co/docs/datasets/image_dataset#imagefolder. In particular, a `metadata.jsonl` file must exist to provide the captions for the images. Ignored if `dataset_name` is specified.
  - name: image_column
    type: str
    default: image
    required: false
    help: The column of the dataset containing an image.
  - name: caption_column
    type: str
    default: text
    required: false
    help: The column of the dataset containing a caption or a list of captions.
  - name: validation_prompt
    type: str
    default: Professional portrait for a CV. The female should appear in business outfit, with a white plain background suitable for professional settings.
    required: false
    help: A prompt that is sampled during training for inference.
  - name: num_validation_images
    type: int
    default: 2
    required: false
    help: Number of images that should be generated during validation with `validation_prompt`.
  - name: validation_epochs
    type: int
    default: 1
    required: false
    help: Run fine-tuning validation every X epochs. The validation process consists of running the prompt `args.validation_prompt` multiple times: `args.num_validation_images`.
  - name: max_train_samples
    type: int
    default: null
    required: false
    help: For debugging purposes or quicker training, truncate the number of training examples to this value if set.
  - name: output_dir
    type: str
    default: "./models"
    required: false
    help: The output directory where the model predictions and checkpoints will be written.
  - name: cache_dir
    type: str
    default: "./models/cache"
    required: false
    help: The directory where the downloaded models and datasets will be stored.
  - name: seed
    type: int
    default: 42069
    required: false
    help: A seed for reproducible training.
  - name: resolution
    type: int
    default: 512
    required: false
    help: The resolution for input images, all the images in the train/validation dataset will be resized to this resolution
  - name: center_crop
    type: bool
    default: false
    required: false
    help: Whether to center crop the input images to the resolution. If not set, the images will be randomly cropped. The images will be resized to the resolution first before cropping.
  - name: random_flip
    type: bool
    default: false
    required: false
    help: whether to randomly flip images horizontally
  - name: train_batch_size
    type: int
    default: 8
    required: false
    help: Batch size (per device) for the training dataloader.
  - name: num_train_epochs
    type: int
    default: 100
    required: false
    help: null
  - name: max_train_steps
    type: int
    default: null
    required: false
    help: Total number of training steps to perform.  If provided, overrides num_train_epochs.
  - name: gradient_accumulation_steps
    type: int
    default: 1
    required: false
    help: Number of updates steps to accumulate before performing a backward/update pass.
  - name: gradient_checkpointing
    type: bool
    default: false
    required: false
    help: Whether or not to use gradient checkpointing to save memory at the expense of slower backward pass.
  - name: learning_rate
    type: float
    default: 1e-4
    required: false
    help: Initial learning rate (after the potential warmup period) to use.
  - name: scale_lr
    type: bool
    default: false
    required: false
    help: Scale the learning rate by the number of GPUs, gradient accumulation steps, and batch size.
  - name: lr_scheduler
    type: str
    default: constant
    required: false
    help: The scheduler type to use. Choose between ["linear", "cosine", "cosine_with_restarts", "polynomial", "constant", "constant_with_warmup"]
  - name: lr_warmup_steps
    type: int
    default: 500
    required: false
    help: Number of steps for the warmup in the lr scheduler.
  - name: snr_gamma
    type: float
    default: null
    required: false
    help: SNR weighting gamma to be used if rebalancing the loss. Recommended value is 5.0. More details here: https://arxiv.org/abs/2303.09556.
  - name: use_8bit_adam
    type: bool
    default: false
    required: false
    help: Whether or not to use 8-bit Adam from bitsandbytes.
  - name: allow_tf32
    type: bool
    default: false
    required: false
    help: Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training. For more information, see https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices
  - name: dataloader_num_workers
    type: int
    default: 2
    required: false
    help: Number of subprocesses to use for data loading. 0 means that the data will be loaded in the main process.
  - name: adam_beta1
    type: float
    default: 0.9
    required: false
    help: The beta1 parameter for the Adam optimizer.
  - name: adam_beta2
    type: float
    default: 0.999
    required: false
    help: The beta2 parameter for the Adam optimizer.
  - name: adam_weight_decay
    type: float
    default: 1e-2
    required: false
    help: Weight decay to use.
  - name: adam_epsilon
    type: float
    default: 1e-08
    required: false
    help: Epsilon value for the Adam optimizer
  - name: max_grad_norm
    type: float
    default: 1.0
    required: false
    help: Max gradient norm.
  - name: push_to_hub
    type: bool
    default: false
    required: false
    help: Whether or not to push the model to the Hub.
  - name: hub_token
    type: str
    default: null
    required: false
    help: The token to use to push to the Model Hub.
  - name: prediction_type
    type: str
    default: null
    required: false
    help: The prediction_type that shall be used for training. Choose between 'epsilon' or 'v_prediction' or leave `None`. If left to `None` the default prediction type of the scheduler: `noise_scheduler.config.prediction_type` is chosen.
  - name: hub_model_id
    type: str
    default: null
    required: false
    help: The name of the repository to keep in sync with the local `output_dir`.
  - name: logging_dir
    type: str
    default: logs
    required: false
    help: [TensorBoard](https://www.tensorflow.org/tensorboard) log directory. Will default to *output_dir/runs/**CURRENT_DATETIME_HOSTNAME***.
  - name: mixed_precision
    type: str
    default: null
    required: false
    choices: ["no", "fp16", "bf16"]
    help: Whether to use mixed precision. Choose between fp16 and bf16 (bfloat16). Bf16 requires PyTorch >= 1.10.and an Nvidia Ampere GPU.  Default to the value of accelerate config of the current system or the flag passed with the `accelerate.launch` command. Use this argument to override the accelerate config.
  - name: report_to
    type: str
    default: tensorboard
    required: false
    help: The integration to report the results and logs to. Supported platforms are `"tensorboard"` (default), `"wandb"` and `"comet_ml"`. Use `"all"` to report to all integrations.
  - name: local_rank
    type: int
    default: -1
    required: false
    help: For distributed training: local_rank
  - name: checkpointing_steps
    type: int
    default: 9999
    required: false
    help: Save a checkpoint of the training state every X updates. These checkpoints are only suitable for resuming training using `--resume_from_checkpoint`.
  - name: checkpoints_total_limit
    type: int
    default: null
    required: false
    help: Max number of checkpoints to store.
  - name: resume_from_checkpoint
    type: str
    default: null
    required: false
    help: Whether training should be resumed from a previous checkpoint. Use a path saved by"' `--checkpointing_steps`, or `"latest"` to automatically select the last available checkpoint.
  - name: enable_xformers_memory_efficient_attention
    type: bool
    default: false
    required: false
    help: "Whether or not to use xformers."
  - name: noise_offset
    type: float
    default: 0
    required: false
    help: "The scale of noise offset."
  - name: rank
    type: int
    default: 4
    required: false
    help: "The dimension of the LoRA update matrices."

# Additional configuration
processed_dataset_path: "./data/processed"  # Path to the processed dataset after running the `make_dataset.py` script.
WANDB_API_KEY: your_actual_wandb_api_key  # Your actual Weights & Biases API key.
PROJECT_NAME: project_name  # Your actual Weights & Biases project name.
ENTITY: entity  # Your actual Weights & Biases entity.
ARTIFACT_NAME: artifact_name  # Your actual Weights & Biases artifact name.
